# ğŸš€ Smart Assistant for Research Summarization

An intelligent **FastAPI + React** platform that ingests research PDFs/TXT, generates concise summaries, answers questions with source-grounded justifications, and tests your understanding with AI-generated challenge questions â€” powered by **Gemini 1.5 Flash + FAISS vector retrieval**.

<img width="1874" height="825" alt="image" src="https://github.com/user-attachments/assets/6d62390f-cfbb-4657-8e4a-68bb8f5b724a" />

---

## âœ¨ Key Features

- ğŸ“„ **Research Paper Summarization**  
  Upload PDF/TXT files to extract text and generate a crisp 150-word summary.

- ğŸ¤– **AI Q&A Chatbot**  
  Ask any question about the uploaded document; responses use FAISS retrieval + Gemini for accuracy.

- ğŸ§  **Challenge Mode**  
  Automatically generates 3 logic questions and evaluates your answers with detailed justifications.

- âš¡ **FAISS + MiniLM Embeddings**  
  Fast, accurate semantic search over document chunks.

- ğŸ¨ **Modern React UI**  
  Smooth neon/glass UI with drag-and-drop upload, history tracking, and real-time responses.

---

## ğŸ“ Project Structure

```
Smart-Assistant-for-Research-Summarization/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py                # FastAPI entry + routes
â”‚   â”‚   â”œâ”€â”€ document_processor.py  # Parsing + summary creation
â”‚   â”‚   â”œâ”€â”€ question_answerer.py   # Q&A using FAISS + Gemini
â”‚   â”‚   â”œâ”€â”€ question_generator.py  # Challenge question generation
â”‚   â”‚   â”œâ”€â”€ answer_evaluator.py    # Challenge evaluation logic
â”‚   â”‚   â””â”€â”€ models/
â”‚   â”‚       â”œâ”€â”€ context.py         # In-memory context store
â”‚   â”‚       â””â”€â”€ document.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ .env                       # GOOGLE_API_KEY
â””â”€â”€ client/
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ App.js
    â”‚   â”œâ”€â”€ index.css
    â”‚   â”œâ”€â”€ axios.js               # Backend base URL
    â”‚   â””â”€â”€ components/
    â”‚       â”œâ”€â”€ FileUpload.js
    â”‚       â”œâ”€â”€ SummaryDisplay.js
    â”‚       â”œâ”€â”€ AskAnything.js
    â”‚       â”œâ”€â”€ ChallengeMe.js
    â”‚       â””â”€â”€ HistoryDisplay.js
    â””â”€â”€ package.json
```

---

## ğŸ› ï¸ Prerequisites

- **Python 3.12**  
- **Node.js 18+**
- **Google Gemini API key**
- Optional: keep repo in a short path (e.g., `C:\sa\project`) to avoid Windows long-path issues.

---

## âš™ï¸ Backend Setup (FastAPI)

```powershell
cd backend
py -3.12 -m venv .venv
Set-ExecutionPolicy -Scope Process -ExecutionPolicy Bypass
./.venv/Scripts/Activate.ps1

python -m pip install --upgrade pip
python -m pip install -r requirements.txt
```

Create `backend/.env`:

```
GOOGLE_API_KEY=your_google_api_key
```

Run backend:

cd C:\RAI\backend; .\venv\Scripts\Activate.ps1; python -m uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

```

---

## ğŸ¨ Frontend Setup (React)

```powershell
cd client
npm install
npm start
# UI: http://localhost:3000
```


If backend URL differs, update:

```
client/src/axios.js
```

---

## ğŸ”Œ API Endpoints

| Method | Endpoint       | Description |
|--------|----------------|-------------|
| POST   | `/upload`      | Upload PDF/TXT â†’ returns `{ text, summary }` |
| POST   | `/ask`         | Ask a question â†’ returns `{ question, answer, justification }` |
| GET    | `/challenge`   | Generate 3 logic questions |
| POST   | `/evaluate`    | Evaluate user answer â†’ returns score + justification |
| GET    | `/`            | Health check |

---

## ğŸ§© How It Works (Data Flow)

1. **User uploads file** â†’ text extracted â†’ summary generated  
2. **Document is chunked** â†’ embedded using MiniLM â†’ stored in FAISS  
3. **User asks a question** â†’ relevant chunks retrieved  
4. **Gemini 1.5 Flash** answers the question + provides justification  
5. **Challenge mode** generates logic Qs and evaluates responses  
6. **Client UI** stores history using local context/session

---

## ğŸ› ï¸ Troubleshooting

- **Long path error (Windows):** move repo to `C:\sa\project`  
- **Missing API key:** ensure `.env` exists and backend restarted  
- **Port conflicts:** edit `uvicorn.run()` in `main.py` and update `axios.js`  
- **No GPU needed:** CPU FAISS + MiniLM is used

---

## ğŸ§¾ Development Notes

- Uses Python 3.12 for smooth dependency support on Windows  
- Summaries are capped at ~10k characters due to Gemini limits  
- FAISS index and session context are in-memory  
- Restarting backend resets state

---

## â­ Final Thoughts

This project combines **AI reasoning**, **retrieval**, and **modern UI** to create a full research assistant experience â€” ideal for academic exploration, paper review, or learning.
